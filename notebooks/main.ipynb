{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "src_path = Path.cwd().parent / 'src'\n",
    "sys.path.append(str(src_path))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import load_data\n",
    "\n",
    "# Set up data paths\n",
    "data_path = Path.cwd().parent / \"data\" / \"ag_news\"\n",
    "train_path = data_path / \"train.csv\"\n",
    "test_path = data_path / \"test.csv\"\n",
    "\n",
    "# Load training data\n",
    "df_train = load_data(train_path)\n",
    "X_train = (df_train[\"Title\"] + \" \" + df_train[\"Description\"]).values\n",
    "y_train = df_train[\"Class Index\"].values\n",
    "\n",
    "# Load test data\n",
    "df_test = load_data(test_path)\n",
    "X_test = (df_test[\"Title\"] + \" \" + df_test[\"Description\"]).values\n",
    "y_test = df_test[\"Class Index\"].values\n",
    "\n",
    "# Show training data\n",
    "# df_train.head()\n",
    "\n",
    "# Show test data\n",
    "# df_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorizer import vectorize_data_fit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Vectorize data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vect = vectorize_data_fit(vectorizer, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_trainer import train_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "lg_model = LogisticRegression()\n",
    "#lg_trained_model = train_model(lg_model, X_train_vect, y_train)\n",
    "\n",
    "# Train Naive Bayes Model\n",
    "nb_model = MultinomialNB()\n",
    "nb_trained_model = train_model(nb_model, X_train_vect, y_train)\n",
    "\n",
    "# Train Random Forest Model\n",
    "rf_model = RandomForestClassifier()\n",
    "#rf_trained_model = train_model(rf_model, X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from perturbation import apply_perturbation\n",
    "\n",
    "# # Save perturbed data to file\n",
    "\n",
    "# X_data = X_test[:1000]\n",
    "# level = 1.0\n",
    "\n",
    "# perturbed_data = apply_perturbation(\n",
    "#     X_data,\n",
    "#     level,\n",
    "#     save_path=f\"perturbed_data/deletion/perturbed_data_{level:.2f}.pkl\"\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Metrics Summary ***\n",
      "robustness_score:  0.0000\n",
      "effective_robustness:  0.0000\n",
      "accuracy:  0.8440\n",
      "*** Results Per Perturbation Level\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perturbation level</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   perturbation level  accuracy\n",
       "0                 0.1     0.844\n",
       "1                 0.2     0.807\n",
       "2                 0.3     0.755\n",
       "3                 0.4     0.730\n",
       "4                 0.5     0.679\n",
       "5                 0.6     0.631\n",
       "6                 0.7     0.591\n",
       "7                 0.8     0.570\n",
       "8                 0.9     0.521\n",
       "9                 1.0     0.431"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from evaluator import evaluate_robustness\n",
    "\n",
    "# Evaluation pipeline\n",
    "\n",
    "# Number of samples to evaluate\n",
    "X_sample = X_test[:1000]\n",
    "y_sample = y_test[:1000]\n",
    "\n",
    "# Define perturbation levels to test\n",
    "perturbation_levels = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "# Add required metrics to evaluate\n",
    "metrics = [\"base_accuracy\", \"robustness_score\", \"effective_robustness\"]\n",
    "\n",
    "# Use filepath when using pertrubed data from files for faster testing\n",
    "file_path = Path(\"perturbed_data/charswap\")\n",
    "\n",
    "results, metrics_summary = evaluate_robustness(\n",
    "    nb_trained_model,\n",
    "    vectorizer,\n",
    "    X_sample, \n",
    "    y_sample,\n",
    "    perturbation_levels,\n",
    "    metrics,\n",
    "    file_path\n",
    ")\n",
    "\n",
    "print(\"*** Metrics Summary ***\")\n",
    "for metric, value in metrics_summary.items():\n",
    "    print(f\"{metric}: {value: .4f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"*** Results Per Perturbation Level\")\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
